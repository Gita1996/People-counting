{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import O_RDONLY\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "from math import sqrt\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "import os\n",
    "from fastapi import FastAPI\n",
    "from fastapi import UploadFile,File\n",
    "from tempfile import NamedTemporaryFile\n",
    "from fastapi.concurrency import run_in_threadpool\n",
    "import aiofiles\n",
    "import asyncio\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "def draw_line(img,left,right,color=(0,0,225),line_thickness=1):\n",
    "\n",
    "  cv2.line(img, left, right, color, thickness=line_thickness) \n",
    "\"\"\"\n",
    "\n",
    "app=FastAPI()\n",
    "@app.post('/people_counting/')\n",
    "\n",
    "async def main(file:UploadFile=File(...)):\n",
    "    \n",
    "    image=Image.open(file.file).convert('RGB')\n",
    "    image.save('people.jpg')\n",
    "    \n",
    "    class opt1:\n",
    "        weight='yolov7-tiny.pt'\n",
    "        source='people.jpg'\n",
    "        img_size=640\n",
    "        conf_thres=0.1\n",
    "        iou_thres=0.45\n",
    "        device=''\n",
    "        view_img=True\n",
    "        save_txt=True\n",
    "        save_conf=True\n",
    "        nosave=True\n",
    "        classes=0\n",
    "        agnostic_nms=True\n",
    "        augment=True\n",
    "        update=True\n",
    "        project='runs/detect'\n",
    "        name='exp'\n",
    "        exist_ok=True\n",
    "        no_trace=True\n",
    "        save_img=True\n",
    "        draw=True\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def counter(founded_people,xyxy,q,top,a):\n",
    "      founded_people[f\"people{q}\"] = [int(xyxy[0]),int(xyxy[1]),int(xyxy[2]),int(xyxy[3])]               \n",
    "      q = q + 1\n",
    "      top = top + xyxy[3] - xyxy[1]\n",
    "      a = True \n",
    "\n",
    "      return founded_people,q,top,a\n",
    "\n",
    "    def distance_counter(img,founded_people,top,q,h,plot_box,det,save_img,b,draw):\n",
    "      #m = people0 #k = [10, 1.0, 12, 7.5] \n",
    "      for ÅŸ, (m, k) in enumerate(founded_people.items()):\n",
    "        for o, (j, l) in enumerate(founded_people.items()):\n",
    "    #      if not m == j:\n",
    "    #        left_1 = np.array([k[0], k[3]])\n",
    "    #        right_1 = np.array([k[2], k[3]])\n",
    "\n",
    "    #        left_2 = np.array([l[0], l[3]])\n",
    "    #        right_2 = np.array([l[2], l[3]])\n",
    "\n",
    "    #        check_point1 = right_1 - left_2\n",
    "    #        check_point2 = left_1 - right_2\n",
    "    #        checks1 = sqrt((check_point1[0]**2) + (check_point1[1]**2))  \n",
    "    #        checks2 = sqrt((check_point2[0]**2) + (check_point2[1]**2))\n",
    "\n",
    "    #        if (checks1 < int((top)/q)/1.2573) or (checks2 < int((top)/q)/1.2573): #75\n",
    "            h += 1\n",
    "            plot_box (img,m,j,founded_people)\n",
    "\n",
    "\n",
    "\n",
    "    #  cv2.putText(img,f\"People count: = {int(h/2)} \",(0, 105), cv2.FONT_HERSHEY_TRIPLEX,1, (255, 0, 0), 1)\n",
    "    #  cv2.putText(img,f\"Total Object: = {len(det)}\",(0, 255), cv2.FONT_HERSHEY_TRIPLEX,1, (200, 100, 0), 1)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_box (image,m,j,founded_people,color=(0,0,225),line_thickness=3):\n",
    "      tl = line_thickness or round(0.002 * (image.shape[0] + image.shape[1]) / 2) + 1\n",
    "      c1, c2= (int(founded_people[m][0]), int(founded_people[m][3])),(int(founded_people[m][2]), int(founded_people[m][3]))\n",
    "      k1, k2= (int(founded_people[j][0]), int(founded_people[j][3])),(int(founded_people[j][2]), int(founded_people[j][3]))\n",
    "      cv2.rectangle(image, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "      cv2.rectangle(image, k1, k2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "\n",
    "    def save(im0,l,b):\n",
    "      bb=im0[int(l[1]):int(l[3]),int(l[0]):int(l[2])]\n",
    "      path=\"/content/gdrive/MyDrive/yolov7/people_imgs\"\n",
    "      bb_resized=cv2.resize(bb,(224,224))\n",
    "\n",
    "    #  cv2.imwrite(os.path.join(path,f\"people_close{b}.jpg\"),bb_resized)\n",
    "      b = b + 1\n",
    "      return b\n",
    "\n",
    "    \"\"\"\n",
    "    def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
    "        # Plots one bounding box on image img\n",
    "        tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "        color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "        if label:\n",
    "            tf = max(tl - 1, 1)  # font thickness\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "            cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "            cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    \"\"\"\n",
    "\n",
    "    def count(classes,image):\n",
    "      model_values=[]\n",
    "      aligns=image.shape\n",
    "      align_bottom=aligns[0]\n",
    "      align_right=(aligns[1]/1.7 ) \n",
    "\n",
    "      for i, (k, v) in enumerate(classes.items()):\n",
    "        a=f\"{k} = {v}\"\n",
    "        model_values.append(v)\n",
    "        align_bottom=align_bottom-35                                                   \n",
    "        cv2.putText(image, str(a) ,(int(align_right),align_bottom), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    def detect(opt, save_img=False):\n",
    "        source, weights, view_img, save_txt, imgsz, trace, save_img, draw = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace, opt.save_img, opt.draw\n",
    "        save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
    "        webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
    "            ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "\n",
    "        # Directories\n",
    "        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "        # Initialize\n",
    "        set_logging()\n",
    "        device = select_device(opt.device)\n",
    "        half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "        # Load model\n",
    "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "        stride = int(model.stride.max())  # model stride\n",
    "        imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "\n",
    "        if trace:\n",
    "            model = TracedModel(model, device, opt.img_size)\n",
    "\n",
    "        if half:\n",
    "            model.half()  # to FP16\n",
    "\n",
    "        # Second-stage classifier\n",
    "        classify = False\n",
    "        if classify:\n",
    "            modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "            modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
    "\n",
    "        # Set Dataloader\n",
    "        vid_path, vid_writer = None, None\n",
    "        if webcam:\n",
    "            view_img = check_imshow()\n",
    "            cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "            dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
    "        else:\n",
    "            dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "\n",
    "        # Get names and colors\n",
    "        names = model.module.names if hasattr(model, 'module') else model.names\n",
    "        colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "        # Run inference\n",
    "        if device.type != 'cpu':\n",
    "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "        old_img_w = old_img_h = imgsz\n",
    "        old_img_b = 1\n",
    "        b = 0\n",
    "        t0 = time.time()\n",
    "        for path, img, im0s, vid_cap in dataset:\n",
    "            img = torch.from_numpy(img).to(device)\n",
    "            img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "            if img.ndimension() == 3:\n",
    "                img = img.unsqueeze(0)\n",
    "\n",
    "            # Warmup\n",
    "            if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
    "                old_img_b = img.shape[0]\n",
    "                old_img_h = img.shape[2]\n",
    "                old_img_w = img.shape[3]\n",
    "                for i in range(3):\n",
    "                    model(img, augment=opt.augment)[0]\n",
    "\n",
    "            # Inference\n",
    "            t1 = time_synchronized()\n",
    "            pred = model(img, augment=opt.augment)[0]\n",
    "            t2 = time_synchronized()\n",
    "\n",
    "            # Apply NMS\n",
    "            pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "            t3 = time_synchronized()\n",
    "\n",
    "            # Apply Classifier\n",
    "            if classify:\n",
    "                pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "            # Process detections\n",
    "            for i, det in enumerate(pred):  # detections per image\n",
    "                if webcam:  # batch_size >= 1\n",
    "                    p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
    "                else:\n",
    "                    p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
    "\n",
    "                p = Path(p)  # to Path\n",
    "                save_path = str(save_dir / p.name)  # img.jpg\n",
    "                txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
    "                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "                if len(det):\n",
    "                    # Rescale boxes from img_size to im0 size\n",
    "                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "                    founded_classes={}\n",
    "                    founded_people={}\n",
    "                    q = 0\n",
    "                    h = 0\n",
    "                    a = None\n",
    "                    top = 0\n",
    "\n",
    "\n",
    "\n",
    "                    # Print results\n",
    "                    for c in det[:, -1].unique():\n",
    "                        if int(c)==0:\n",
    "                            n = (det[:, -1] == c).sum()  # detections per class\n",
    "                            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "        #                    print(names[int(c)])\n",
    "                            class_index=int(c)\n",
    "                            count_of_object=int(n)\n",
    "                            founded_classes[names[class_index]]=int(n)\n",
    "                            count(classes=founded_classes,image=im0)\n",
    "\n",
    "\n",
    "                    # Write results\n",
    "                    for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "                        if save_txt: # Write to file\n",
    "                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                            line = (cls, *xywh, conf) if opt.save_conf else (cls, *xywh)  # label format\n",
    "                            with open(txt_path + '.txt', 'a') as f:\n",
    "                              f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "                        if cls == 0:\n",
    "                          founded_people,q,top,a = counter(founded_people,xyxy,q,top,a)\n",
    "                          \"\"\"\n",
    "                          left_middle = [int(xyxy[0]), int(xyxy[3])]\n",
    "                          right_middle = [int(xyxy[2]),int(xyxy[3])]\n",
    "\n",
    "                          \"\"\"\n",
    "\n",
    "                        if save_img or view_img:  # Add bbox to image\n",
    "    #                        label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                            plot_one_box(xyxy, im0, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "                    if a == True:\n",
    "                      distance_counter(im0,founded_people,top,q,h,plot_box,det,save_img,b,draw)\n",
    "\n",
    "                # Print time (inference + NMS)\n",
    "                print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n",
    "\n",
    "                # Stream results\n",
    "                if view_img:\n",
    "                    cv2.imshow(str(p), im0)\n",
    "                    cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "                # Save results (image with detections)\n",
    "                if save_img:\n",
    "                    if dataset.mode == 'image':\n",
    "                        cv2.imwrite(save_path, im0)\n",
    "                        print(f\" The image with the result is saved in: {save_path}\")\n",
    "                    else:  # 'video' or 'stream'\n",
    "                        if vid_path != save_path:  # new video\n",
    "                            vid_path = save_path\n",
    "                            if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                                vid_writer.release()  # release previous video writer\n",
    "                            if vid_cap:  # video\n",
    "                                fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                            else:  # stream\n",
    "                                fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                                save_path += '.mp4'\n",
    "                            vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                        vid_writer.write(im0)\n",
    "\n",
    "        if save_txt or save_img:\n",
    "            s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "            #print(f\"Results saved to {save_dir}{s}\")\n",
    "\n",
    "        print(f'Done. ({time.time() - t0:.3f}s)')\n",
    "        \n",
    "        return n\n",
    "\n",
    "\n",
    "    opt=opt1()\n",
    "        \n",
    "        #check_requirements(exclude=('pycocotools', 'thop'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if opt.update:  # update all models (to fix SourceChangeWarning)\n",
    "            m=detect(opt)\n",
    "            l={'people count':m}\n",
    "            return l\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
